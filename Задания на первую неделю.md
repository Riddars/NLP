

# Задание 1
## 1. Токенизация

* Найдите любой текст  
* Разделите его на предложения  
* Разделите предложения на токены  
* Приведите токены к нормальной форме (нормализуйте)  
* Создайте словарь (vocabulary)

## 2. Кодирование пар байтов (Byte-Pair Encoding)

* Реализуйте алгоритм  
* Постройте словарь  
* Преобразуйте текст в идентификаторы токенов (опционально)

---

# Задание 2: N-граммные модели

> Реализуйте N-граммную модель  
  * Постройте модель для произвольного значения n  
  * Реализуйте сглаживание  
  * Сгенерируйте текст, используя "обученную" модель

---

# Задание 3: Word2Vec

> Реализуйте модель векторных представлений слов  
  * Можно реализовать только одну из двух моделей: CBOW или Skip-gram  
  * Разрешается использовать библиотеки, такие как PyTorch, TensorFlow и другие, для построения нейросети и обучения модели  
  * Реализуйте поиск по эмбеддингам и выведите наиболее похожие слова для заданного слова из словаря

---

# Задание 4: RNN

Реализуйте модель на основе рекуррентных нейронных сетей (RNN)  
  * Выберите одну из задач: распознавание сущностей, классификация текста или генерация следующего токена  
  * Постройте и обучите модель RNN для выбранной задачи  
  * Убедитесь, что модель включает слой эмбеддингов, как минимум один RNN-слой и линейное преобразование перед выходом  
  * Продемонстрируйте работу модели на любых примерах

---

# Задание 5: (необязательное)

Раздельно реализуйте модуль обучения эмбеддингов и используйте предобученные эмбеддинги вместо слоя эмбеддингов перед RNN.
